<div id="top" align="center">

<p align="center">
  <img src="assets/images/repo/logo.jpg" alt="NexusAD Logo" width="200">
</p>

# **NexusAD**  
*Multimodal Perception and Comprehension of Corner Cases in Autonomous Driving*

Authors <a name="authors"></a>
Mengjingcheng Mo, Jingxin Wang, Like Wang, Haosheng Chen, Changjun Gu, Jiaxu Leng, Xinbo Gao
Chongqing University of Posts and Telecommunications

**æ³¨æ„ï¼šç›®å‰ä»£ç è¿˜åœ¨æ›´æ–°ä¸­ï¼Œæ•¬è¯·æœŸå¾…æ›´å¤šåŠŸèƒ½å’Œæ”¹è¿›ã€‚**

`ECCV 2024 Autonomous Driving Workshop` **Corner Case Scene Understanding** [Leaderboard](https://eccv2024.autonomousdriving.com)

</div>

---

<div id="top" align="center">

[![Project Page](https://img.shields.io/badge/Project%20Page-8A2BE2)](https://opendrivelab.com/DriveLM/)
[![License: MIT](https://img.shields.io/badge/license-MIT-blue.svg)](#license)
[![arXiv](https://img.shields.io/badge/arXiv-2312.14150-b31b1b.svg)](https://openreview.net/forum?id=example-link)
[![Latest Release](https://img.shields.io/badge/Latest%20release-v1.1-yellow)](#getting-started)

</div>

---

## é¡¹ç›®äº®ç‚¹ <a name="highlight"></a>

- ğŸ”¥ **NexusAD** æå‡ºäº†ä¸€ç§åŸºäº **InternVL-2.0** çš„å¤šæ¨¡æ€æ„ŸçŸ¥ä¸ç†è§£æ¡†æ¶ï¼Œé€šè¿‡å¯¹ **CODA-LM** æ•°æ®é›†çš„ç²¾ç»†è°ƒä¼˜ï¼Œæ˜¾è‘—æå‡äº†å¯¹å¤æ‚åœºæ™¯çš„æ£€æµ‹ã€æ·±åº¦ä¼°è®¡ä¸æ¨ç†èƒ½åŠ›ã€‚
- ğŸ **NexusAD** å‚ä¸äº† [**`ECCV 2024 Autonomous Driving Workshop`**](https://eccv2024.autonomousdriving.com)ï¼Œä¸“æ³¨äºæç«¯é©¾é©¶åœºæ™¯ä¸­çš„å¤šæ¨¡æ€åœºæ™¯ç†è§£ä»»åŠ¡ã€‚

<p align="center">
  <img src="assets/images/repo/nexusad_architecture.jpg" alt="NexusAD Architecture" width="600">
</p>

---

## æœ€æ–°åŠ¨æ€ <a name="news"></a>

- **2024/09/08**: NexusAD åœ¨ ECCV 2024 æäº¤ï¼Œå¹¶å–å¾— 68.97 åˆ†çš„æˆç»©ã€‚
- **2024/06/01**: NexusAD å›¢é˜Ÿå‘å¸ƒäº†æœ€æ–°ç‰ˆæœ¬çš„ä»£ç å’Œè®­ç»ƒæ•°æ®ã€‚

<p align="right">(<a href="#top">å›åˆ°é¡¶éƒ¨</a>)</p>

---

## ç›®å½•

1. [é¡¹ç›®äº®ç‚¹](#highlight)
2. [å¿«é€Ÿå¼€å§‹](#getting-started)
3. [æ¨¡å‹æ¶æ„](#model-architecture)
4. [å®éªŒç»“æœ](#results)
5. [è´¡çŒ®æŒ‡å—](#contributing)
6. [è®¸å¯ä¸å¼•ç”¨](#license)

---

## å¿«é€Ÿå¼€å§‹ <a name="getting-started"></a>

è¯·æŒ‰ç…§ä»¥ä¸‹æ­¥éª¤å¼€å§‹ä½¿ç”¨ NexusADï¼š

1. **å…‹éš†ä»“åº“**ï¼š
   ```bash
   git clone https://github.com/OpenVisualLab/NexusAD.git
   cd NexusAD
   ```

2. **å®‰è£…ä¾èµ–**ï¼š
   ```bash
   pip install -r requirements.txt
   ```

3. **ä¸‹è½½ [CODA-LM æ•°æ®é›†](https://example.com/coda-lm-dataset)** å¹¶å°†å…¶æ”¾ç½®åœ¨æŒ‡å®šç›®å½•ä¸­ã€‚

4. **ä¸‹è½½ [LoRA æƒé‡](https://example.com/lora-weights)** å¹¶æ”¾ç½®åœ¨ `weights/` ç›®å½•ä¸‹ã€‚

5. **è¿è¡Œæ¨¡å‹**ï¼š
   ```bash
   python preprocess.py --data_path <path-to-CODA-LM>
   python train.py --config config.json
   python evaluate.py --data_path <path-to-evaluation-set>
   ```

<p align="right">(<a href="#top">å›åˆ°é¡¶éƒ¨</a>)</p>

---

## æ¨¡å‹æ¶æ„ <a name="model-architecture"></a>

NexusAD æ¨¡å‹æ¶æ„ç”±ä»¥ä¸‹å‡ éƒ¨åˆ†ç»„æˆï¼š

1. **åˆæ­¥è§†è§‰æ„ŸçŸ¥**ï¼šä½¿ç”¨ **Grounding DINO** è¿›è¡Œå¯¹è±¡æ£€æµ‹ï¼Œä½¿ç”¨ **DepthAnything v2** è¿›è¡Œæ·±åº¦ä¼°è®¡ï¼Œå°†ç©ºé—´ä¿¡æ¯è½¬æ¢ä¸ºæ˜“äºç†è§£çš„ç»“æ„åŒ–æ–‡æœ¬ã€‚
   
2. **åœºæ™¯æ„ŸçŸ¥å¢å¼ºæ£€ç´¢ç”Ÿæˆ**ï¼šä½¿ç”¨ **Retrieval-Augmented Generation (RAG)** æŠ€æœ¯ï¼Œæ£€ç´¢å’Œé€‰æ‹©ç›¸å…³æ ·æœ¬ä»¥å¢å¼ºå¯¹å¤æ‚é©¾é©¶åœºæ™¯çš„ç†è§£ã€‚

3. **é©¾é©¶æç¤ºä¼˜åŒ–**ï¼šé€šè¿‡ **Chain-of-Thought (CoT)** æç¤ºï¼Œç”ŸæˆåŸºäºä¸Šä¸‹æ–‡çš„ç»“æ„åŒ–é©¾é©¶å»ºè®®ã€‚

4. **ç²¾ç»†è°ƒä¼˜**ï¼šæˆ‘ä»¬ä½¿ç”¨ **LoRA** æŠ€æœ¯è¿›è¡Œé«˜æ•ˆçš„å‚æ•°å¾®è°ƒï¼Œä»¥ä¼˜åŒ–æ€§èƒ½å¹¶èŠ‚çœè®¡ç®—èµ„æºã€‚

<p align="right">(<a href="#top">å›åˆ°é¡¶éƒ¨</a>)</p>

---

## å®éªŒç»“æœ <a name="results"></a>

åœ¨ ECCV 2024 çš„è§’è½æ¡ˆä¾‹ç†è§£ä»»åŠ¡ä¸­ï¼ŒNexusAD çš„è¡¨ç°è¶…è¿‡äº†åŸºå‡†æ¨¡å‹ï¼Œå–å¾—äº† **68.97** çš„æœ€ç»ˆå¾—åˆ†ï¼š

| æ¨¡å‹                | ä¸€èˆ¬æ„ŸçŸ¥   | åŒºåŸŸæ„ŸçŸ¥   | é©¾é©¶å»ºè®®   | æœ€ç»ˆå¾—åˆ†  |
|--------------------|------------|------------|------------|----------|
| GPT-4V             | 57.50      | 56.26      | 63.30      | 59.02    |
| CODA-VLM           | 55.04      | 77.68      | 58.14      | 63.62    |
| InternVL-2.0-26B   | 43.39      | 64.91      | 48.04      | 52.11    |
| **NexusAD (Ours)** | **57.58**  | **84.31**  | **65.02**  | **68.97**|

<p align="right">(<a href="#top">å›åˆ°é¡¶éƒ¨</a>)</p>

---

## è´¡çŒ®æŒ‡å— <a name="contributing"></a>

æˆ‘ä»¬æ¬¢è¿ä»»ä½•å½¢å¼çš„è´¡çŒ®ï¼è¯·æŸ¥çœ‹ [CONTRIBUTING.md](CONTRIBUTING.md) äº†è§£å¦‚ä½•å‚ä¸ã€‚

<p align="right">(<a href="#top">å›åˆ°é¡¶éƒ¨</a>)</p>

---

## è®¸å¯ä¸å¼•ç”¨ <a name="license"></a>

æœ¬é¡¹ç›®æ ¹æ® [MIT è®¸å¯](./LICENSE) å‘å¸ƒã€‚å¦‚æœè¯¥é¡¹ç›®å¯¹ä½ çš„ç ”ç©¶æœ‰å¸®åŠ©ï¼Œè¯·å¼•ç”¨ä»¥ä¸‹å†…å®¹ï¼š

```BibTeX
@article{mo2024nexusad,
  title={NexusAD: Multimodal Perception and Comprehension of Corner Cases in Autonomous Driving},
  author={Mo, Mengjingcheng and Wang, Jingxin and Wang, Like and Chen, Haosheng and Gu, Changjun and Leng,Jiaxu and Gao, Xinbo},
  journal={ECCV 2024 Autonomous Driving Workshop Abstract Paper},
  year={2024}
}
```

<p align="right">(<a href="#top">å›åˆ°é¡¶éƒ¨</a>)</p>

